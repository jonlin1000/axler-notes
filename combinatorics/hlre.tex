One of the most basic combinatorial questions that one can ask is ``What is the number/how many objects are there?''
In the last section we set up the machinery of \textit{generating functions}, where we put a parametrized family into a sequence and we operated on it using a so called ``generating function'' approach.

Here is an example of the power of this approach. Consider the problem of finding a formula for the sequence
\[1, 2, 5, 14, 41, \dots\]
satisfying $f(n+2) = 4f(n + 1) - 3f(n)$ for $n \geq 0$.

Setting up the generating function 
\[F(x) = \sum_{k = 0}^{\infty}f(n)x^n\] we rearrange and we find
\begin{align*}
F(x) &= \sum_{k = 0}^{\infty}f(n)x^n \\
&= f(0) + f(1)x + \sum_{k = 2}^{\infty}f(n)x^n \\
&= f(0) + f(1)x + \sum_{k = 0}^{\infty}(4f(n + 1) - 3f(n))x^{n + 2} \\
&= f(0) + f(1)x - 4x + 4x\sum_{k = 0}^{\infty}f(n)x^n - 3x^2\sum_{k = 0}^{\infty}f(n)x^n \\
&= f(0) + (f(1) - 4)x + (4x - 3x^2)F(x)
\end{align*}
which implies that 
\[F(x)(1 - 4x + 3x^2) = f(0) + (f(1) - 4)x.\]

Conversely, any formal power series of the form $\frac{ax + b}{1 - 4x + 3x^2}$ is a solution to the recurrence relation. Since $1 - 4x + 3x^2 = (1-x)(1-3x)$, by partial fraction decomposition we have
\[\frac{ax + b}{1 - 4x + 3x^2} = \frac{c}{1-x} + \frac{d}{1-3x}.\] By the geometric series formula of last chapter, this is equal to $c(1 + x + x^2 + x^3 + \cdots) + d(1 + 3x + 9x^2 + 27x^3 + \cdots)$. We conclude that 
\[f(n) = c + d3^n\] for arbitrary $c$ and $d$ are all the solutions to this recurrence relation.


In this section, instead of using the ring structure of the formal power series $F[[x]]$ we will put a vector space structure on the set of infinite sequences.

Observe that the equation $f(n + 2) = 4f(n + 1) - 3f(n)$ is \textbf{linear}. That is, if $f_1$, and $f_2$ satisfy this recurrence relation, so does $g = Af_1 + bf_2$, where $A$ and $B$ are arbitrary constants. This implies that the set of solutions to this linear recurrence relation is a vector space (namely, a subspace of the $\mathbb{F}^{\omega}$ sequence space). Here are some elements of this vector space:
\begin{align*}
(1, 1, 1, 1, 1, \dots) \\
(1, 3, 9, 27, \dots) \\
(1, 0, -3, -12, -39, \dots) \\
(0, 1, 4, 13, 40, \dots) \\
\end{align*}

This vector space is 2-dimensional: every sequence is completely determined by the first two elements. One might notice that either the first two elements above or the last two elements above form a basis. The first two elements are nice in that they have simple formulas, namely $1^n$ and $3^n$. The last two are nice because they can be seen to be like a standard basis for the vector space, and you can easily express any other sequence in the vector space in terms of a linear combination of the two.

\begin{definition}
Any recurrence relation of the form
\[\sum_{j = 0}^kA_jf(n + j) = 0\]
where the $A_j$ are constants is called a $k$th order homogeneous linear recurrence relation with constant coefficients.
\end{definition}

There are certainly important recurrence relations where the coefficients are non-constant, consider the simple example
\[(n + 1)! = (n+1)(n!).\]

For the rest of this section, let $S$ be the vector space of all sequences
\[f = (f(0), f(1), f(2), \dots)\] called the \textit{sequence space}. For any sequence $f$, define $T(f)$ (or $Tf$) as the sequence whose value at $n$ is $f(n + 1)$. In other words, $T$ is the ``left shift'' operator. It is easy to see that $T$ is linear. If we view it as an infinite diagonal matrix, then $T$ is zero everywhere except $1$ on the diagonal just above the main diagonal.

Now observe that the recurrence relation
\[f(n + 2) - 4f(n + 1) + 3f(n) = 0\] can be written as
\[T^2(f) - 4T(f) + 3f = 0.\] Note that the $0$ in the above equation is the zero sequence $(0, 0, 0, \dots)$, and not the zero of the field. $T^2$ denotes $T \circ T$.

This act of representing recurrence relations as polynomials of this shift operator is very powerful, as we shall see. Let's see what $T - 3I$ does to a vector of the form $f(n) = r^n$. We have that
\begin{align*}
(T - 3I)f(n) &= Tf(n) - 3If(n) \\
&= r^{n + 1} - 3r^n \\
&= (3 - r)r^n.
\end{align*}

That is, $f$ is an eigenvector of $T - 3I$ with eigenvalue $r - 3$. In particular, if $r = 3$, then $f$ is annihilated by $T - 3I$. Observe that $(T-I)(T-3I)$ annihilates $f(n) = 3^n$ and $(T-3I)(T-I)$ annihilates $f(n) = 1^n$.

But by linearity, both these operators are equal! Hence any linear combination of $f_2(n) = 3^n$ and $f_1(n) = 1$ is in the kernel of $T^2 - 4T + 3I$, and therefore satisfies the recurrence relation we were interested in above.

Let's introduce some new terminology. The operator $T - I$ (also sometimes written $T - 1$) is called the \textit{difference operator} (compare with the derivative operator). The equation $p(T)f = 0$ for any polynomial $p$ is called a \textit{difference equation}.

Here is the first result of a more general theorem:
\begin{theorem}
Let $p(t) = a_dt^d + a_{d-1}t^{d-1} + \cdots + a_0$, and consider the equation $p(T)f = 0$, a homogeneous linear recurrence equation with constant coefficients.

Suppose $p(t)$ has $d$ distinct roots. Then the general solution to the linear recurrence relation $p(T)f = 0$ is of the form
\[f(n) = A_1r_1^n + A_2r_2^n + \cdots + A_dr_d^n,\] where the $r_i$ are the roots of $p(t)$.
\end{theorem}
\begin{proof}
It is easy to check that $f(n) = r_i^n$ is a solution to the linear recurrence equation we are considering. These $d$ functions are linearly independent, since they are all eigenvectors of the left shift operator $T$ with distinct eigenvalues.  Snce we know that the subspace of the sequence space consisting of $\ker(p(T))$ is $d$-dimensional, we are done.
\end{proof}

Note that even if the terms of the sequence $f(n)$ are integers, the numbers $r_i$ and $A_i$ need not be. 

But what if our polynomial doesn't have repeated roots? For example, take $p(t) = t^2 - 2t + 1$. Using a standard method (such as the one in the beginning of this section), we get a $2$ parameter family of generating functions
\[\frac{ax + b}{x^2 - 2x + 1}.\] When $a = -1$ and $b = 1$ we can simplify to get the formal power series
\[1 + x + x^2 + x^3 + \cdots.\]
Put $a=  1$, $b = 0$ to get
\[\frac{x}{1-2x + x^2} = x(1-x)^{-2} = x(1 + 2x + 3x^2 + 4x^3 + \cdots) = x + 2x^2 = 3x^3 + \cdots.\]

then we have two ``fundamental solutions'' $f(n) = 1$, $g(n) = n$.

In general, it turns out that if $p(T) = (T - rI)^d$, there are $d$ fundamental solutions $f(n) = n^kr^n$ for $k = 0$ to $d-1$. When $r = 1$, these fundamental solutions are polynomials and the general solution is a polynomial of degree less than or equal to $d$.

\begin{theorem}
If $p(t)$ is degree $d$, with leading coefficient and constant term non-zero, the solutions of $p(T)f = 0$ form a $d$-dimensional space with basis elements of the form $n^kr^n$, where $r$ is any root of $p(t) = 0$ and $k$ is any non-negative integer less than the multiplicity of $r$ in $p$.
\end{theorem}

\begin{proof}
omitted for now
\end{proof}

\begin{theorem}
If $f$ satisfies a homogeneous linear recurrence equation of order $d$, then $f, Tf, T^2f, \dots, T^df$ are linearly dependent.

Conversely, if $f, Tf, T^2f, \dots$ span a $d$-dimensional sequence space, then $f$ satisfies a linear recurrence equation of order $d$.
\end{theorem}
\begin{proof}
Exercise to reader; follows from basic properties of dimension in finite dimensional vector spaces.
\end{proof}